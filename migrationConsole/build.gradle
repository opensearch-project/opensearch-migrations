import org.opensearch.migrations.common.CommonUtils
import com.bmuschko.gradle.docker.tasks.image.DockerBuildImage
import com.github.gradle.node.npm.task.NpmTask

plugins {
    id 'org.opensearch.migrations.java-library-conventions'
    id 'com.bmuschko.docker-remote-api'
    id 'com.github.node-gradle.node' version '7.1.0'
}

node {
    version = '22.14.0'
    download = true
}

// Define paths at the top level
def orchestrationSpecsDirP = rootProject.layout.projectDirectory.dir("orchestrationSpecs")
def orchestrationP     = orchestrationSpecsDirP
def configProcessorP   = orchestrationP.dir("packages/config-processor")
def workflowTemplatesP = orchestrationP.dir("packages/migration-workflow-templates")
def configProcessorStagingP =
        layout.buildDirectory.dir("dockerContext/nodeStaging/configProcessor")
def workflowTemplatesStagingP =
        layout.buildDirectory.dir("dockerContext/nodeStaging/workflowTemplates")

tasks.register('installDependencies', NpmTask) {
    description = 'Install npm dependencies for orchestrationSpecs'
    workingDir = orchestrationSpecsDirP.asFile
    args = ['ci', '--force', '--omit=optional']

    inputs.file(orchestrationSpecsDirP.file("package.json"))
    inputs.file(orchestrationSpecsDirP.file("package-lock.json"))
    outputs.dir(orchestrationSpecsDirP.dir("node_modules"))
}

tasks.register('makeAndStageWorkflowTemplates', NpmTask) {
    description = 'Build the workflow templates from their TypeScript definitions'
    workingDir = workflowTemplatesP.asFile
    args = ['run', 'check-and-make-templates', '--', '--outputDirectory', workflowTemplatesStagingP.get().asFile.absolutePath]
    dependsOn installDependencies

    inputs.dir(workflowTemplatesP.dir("src"))
    outputs.dir(workflowTemplatesStagingP)

    doFirst {
        workflowTemplatesStagingP.get().asFile.mkdirs()
    }
}

tasks.register('buildAndStageConfigProcessor', NpmTask) {
    description = 'Build and stage the config-processor TypeScript package directly to staging'
    workingDir = configProcessorP.asFile
    args = ['run', 'check-and-bundle', '--', configProcessorStagingP.get().asFile.absolutePath]
    dependsOn installDependencies

    inputs.dir(configProcessorP.dir("src"))
    inputs.file(configProcessorP.file("makeBundle.js"))
    outputs.dir(configProcessorStagingP)

    doFirst {
        configProcessorStagingP.get().asFile.mkdirs()
    }
}

tasks.register('syncDockerBuildContext', Sync) {
    into layout.buildDirectory.dir("dockerContext")
    duplicatesStrategy = DuplicatesStrategy.EXCLUDE

    dependsOn makeAndStageWorkflowTemplates
    dependsOn buildAndStageConfigProcessor

    // Copy your Dockerfile and any other docker-related files
    from(project.file("Dockerfile"))
//    from(project.file("__init__.py"))
    from(project.file("kafkaCmdRef.md"))
    from(project.file("kafkaExport.sh"))
    from(project.file("loadServicesFromParameterStore.sh"))
    from(project.file("msk-iam-auth.properties"))
    from(project.file("setupVimSchemaChecker.sh"))
    from(project.file("start-console.sh"))

    def commonExcludes = [
            "**/.venv/**",
            "**/.vscode/**",
            "**/node_modules/**",
            "**/__pycache__/**",
            "**/.pytest_cache/**"
    ]
    from(project.file("cluster_tools")) {
        into "cluster_tools"
        exclude commonExcludes
    }
    from(project.file("lib/console_link/console_link")) {
        into "lib/console_link/console_link"
        exclude commonExcludes
    }
    from(project.file("lib/console_link/Pipfile")) {
        into "lib/console_link"
        exclude commonExcludes
    }
    from(project.file("lib/console_link/Pipfile.lock")) {
        into "lib/console_link"
        exclude commonExcludes
    }
    from(project.file("lib/console_link/setup.py")) {
        into "lib/console_link"
        exclude commonExcludes
    }
    from(project.file("lib/integ_test")) {
        into "lib/integ_test"
        exclude commonExcludes
    }
    from(project.file("workflows")) {
        into "workflows"
        exclude commonExcludes
    }

    // Preserve the nodeStaging directory if it exists
    preserve {
        include 'nodeStaging/**'
    }
}

// Build the base migration console image with Python libraries and scripts
tasks.register('buildDockerImage_migrationConsoleBase', DockerBuildImage) {
    // Depend on the elasticsearch test console base image
    dependsOn ":TrafficCapture:dockerSolution:buildDockerImage_elasticsearch_client_test_console"
    // Depend on console_link's generated OpenAPI spec (copied into Docker image)
    dependsOn ":console_link:generateOpenApiSpec"
    dependsOn syncDockerBuildContext

    def dockerImageName = "migration_console_base"
    def projectName = "migrationConsoleBase"

    inputDir = layout.buildDirectory.dir("dockerContext").get().asFile

    def hashNonce = CommonUtils.calculateDockerHash(project.fileTree(inputDir) {
        exclude '**/.venv/**', '**/.gradle/**', '**/build/**', '**/.pytest_cache/**', '**/__pycache__/**'
    })
    images.add("migrations/${dockerImageName}:${hashNonce}".toString())
    images.add("migrations/${dockerImageName}:latest".toString())
}
