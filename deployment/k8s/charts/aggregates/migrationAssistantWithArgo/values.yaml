conditionalPackageInstalls:
  # Migration infrastructure components
  etcd: true                    # used by our Argo workflows for workflow coordination. May be used by strimzi clusters too
  cert-manager: true            # needed by the otel operator
  kube-prometheus-stack: true   # will be needed for auto-scaling
  argo-workflows: true          # orchestrates the steps of a migration
  strimzi-kafka-operator: true  # Required by capture and replay
  fluent-bit: true

  # Simpler alternative to the opentelemetry-operator.
  # ONLY set up the otel-collector and require manual instrumentation
  # Mutually exclusive with otel-collector
  otel-collector-daemonset: true
  # EXPERIMENTAL!  Needed for auto-instrumenting and general observability.
  # Mutually exclusive with otel-collector-daemonset
  opentelemetry-operator: false

  # Support packages - installed as direct dependencies to this chart as opposed to via the installer job
  migration-console: true

  # Packages for testing and local development
  localstack: true
  # Nice to haves that aren't fully supported yet
  gatekeeper: false
  grafana: false
  jaeger: true

images:
  captureProxy:
    repository: migrations/capture_proxy
    tag: latest
    pullPolicy: IfNotPresent
  trafficReplayer:
    repository: migrations/traffic_replayer
    tag: latest
    pullPolicy: IfNotPresent
  reindexFromSnapshot:
    repository: migrations/reindex_from_snapshot
    tag: latest
    pullPolicy: IfNotPresent
  migrationConsole:
    repository: migrations/migration_console
    tag: latest
    pullPolicy: IfNotPresent
  installer:
    repository: migrations/migration_console
    tag: latest
    pullPolicy: IfNotPresent
  etcdUtils:
    repository: migrations/migration_console
    tag: latest
    pullPolicy: IfNotPresent

# Default AWS values are dummy values for LocalStack usage
aws:
  configureAwsEksResources: false
  region: us-east-2
  account: "123456789012"

stageName: dev
developerModeEnabled: false

defaultBucketConfiguration:
  create: true
  deleteOnUninstall: true
  emptyBeforeDelete: true
  useLocalStack: true
  endpoint: localstack
  serviceAccountName: "migrations-service-account"
  bucketOperationImage: "amazon/aws-cli:2.25.11"
  bucketOperationImagePullPolicy: "IfNotPresent"

logs:
  sharedLogsVolume:
    enabled: true
    name: logs-pvc
    size: 10Gi
    storageClass: ""
  format: application # application or docker-json


installer:
  serviceAccount:
    create: true
    name: "migrations-service-account"
  rbac:
    create: true

# For OTEL Operator
extraOtelConfiguration:
  version: "0.124.0"
  configs:
    metrics:
      - prometheus
      - cloudwatch
    traces:
      - jaeger
      - xray

# For OTEL Daemonset
otelConfiguration:
  serviceAccountName: "migrations-service-account"
  collectorConfig: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
    processors:
      batch:
        timeout: 10s
        send_batch_size: 8192
        send_batch_max_size: 10000
    extensions:
      zpages:
        endpoint: :55679
      pprof:
        endpoint: :1888
      health_check:
    exporters:
      debug:
        verbosity: detailed
        sampling_initial: 5
        sampling_thereafter: 200
      prometheus:
        endpoint: "0.0.0.0:8889"
        send_timestamps: true
        metric_expiration: 5m
        enable_open_metrics: true
      otlp/jaeger: # Jaeger supports OTLP directly. The default port for OTLP/gRPC is 4317
        endpoint: jaeger-collector:4317
        tls:
          insecure: true
    service:
      extensions: [ zpages, pprof, health_check ]
      pipelines:
        metrics:
          receivers: [ otlp ]
          processors: [ batch ]
          exporters: [ prometheus ]
        traces:
          receivers: [ otlp ]
          processors: [ batch ]
          exporters: [ otlp/jaeger ]
        logs:
          receivers: [ otlp ]
          processors:
          exporters: [ debug ]

charts:
  # Coordinate workflows, maybe RFS, maybe more
  etcd:
    version: "1.1.2"
    repository: "https://groundhog2k.github.io/helm-charts"
    values:
      preUpgrade:
        enabled: false
      replicaCount: 1
      auth:
        rbac:
          rootPassword: password
      resources:
        requests:
          cpu: 1
          memory: 2Gi
        limits:
          cpu: 2
          memory: 4Gi
      persistence:
        enabled: false
      #    storageClass: "standard"
      #    size: 10Gi
      service:
        type: ClusterIP
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true
      extraEnvVars:
        - name: ETCD_AUTO_COMPACTION_RETENTION
          value: "1"
        - name: ETCD_QUOTA_BACKEND_BYTES
          value: "8589934592" # 8GB
        - name: ETCD_HEARTBEAT_INTERVAL
          value: "100"
        - name: ETCD_ELECTION_TIMEOUT
          value: "1000"
      startFromSnapshot:
        enabled: false
      serviceAccount:
        create: true
      podSecurityContext:
        fsGroup: 1001
        runAsUser: 1001

  cert-manager:
    version: 1.17.2
    repository: https://charts.jetstack.io
    values:
      crds:
        enabled: true

  opentelemetry-operator:
    version: "0.86.4"
    repository: "https://open-telemetry.github.io/opentelemetry-helm-charts"
    timeout: 300
    dependsOn: cert-manager
    values:
      admissionWebhooks:
        certManager:
          enabled: true # default
      crds:
        create: true
      manager:
        verticalPodAutoscaler:
          enabled: false # default
        collectorImage:
          repository: "public.ecr.aws/aws-observability/aws-otel-collector"
          tag: "0.43.2"


  strimzi-kafka-operator:
    version: 0.47.0
    repository: "https://strimzi.io/charts/"
    values:
      replicas: 1
      storageType: ephemeral
      storageSize: 100Gi
      storageDeleteClaim: true
      dedicatedController:
        replicas: 1
        storageSize: 10Gi

      readinessProbe:
        initialDelaySeconds: 5
        periodSeconds: 2
        timeoutSeconds: 3
        failureThreshold: 1
      livenessProbe:
        initialDelaySeconds: 5
        periodSeconds: 2
        timeoutSeconds: 3
        failureThreshold: 1

      kafka:
        template:
          pod:
            readinessProbe:
              initialDelaySeconds: 5
              periodSeconds: 5
              timeoutSeconds: 3
              failureThreshold: 1

        readinessProbe:
          initialDelaySeconds: 5
          periodSeconds: 2
          timeoutSeconds: 3
          failureThreshold: 1
        livenessProbe:
          initialDelaySeconds: 5
          periodSeconds: 2
          timeoutSeconds: 3
          failureThreshold: 1

  argo-workflows:
    version: "0.45.24"
    repository: "https://argoproj.github.io/argo-helm"
    values:
      fullnameOverride: "argo"
      images:
        pullPolicy: IfNotPresent
      controller:
        containerSecurityContext:
          runAsNonRoot: true
          allowPrivilegeEscalation: false
        clusterWorkflowTemplates:
          enabled: false
        metricsConfig:
          enabled: true
        resourceRateLimit: { "limit": 10.0, "burst": 25 }
        workflowWorkers: 16
      mainContainer:
        env:
          - name: RESOURCE_STATE_CHECK_INTERVAL
            value: "1s"
      executor:
        env:
          - name: RESOURCE_STATE_CHECK_INTERVAL
            value: "1s"
      server:
        extraArgs:
          - --auth-mode=server
      serviceAccount:
        create: true
      singleNamespace: true
      # Extra workflow configuration
      workflow:
        serviceAccount:
          create: false
          name: argo-workflow-executor

  fluent-bit:
    version: "0.49.0"
    repository: "https://fluent.github.io/helm-charts"
    values:
      env:
        - name: OUTPUT_FORMAT
          valueFrom:
            configMapKeyRef:
              name: log-aggregation-config
              key: OUTPUT_FORMAT

      extraVolumes:
        - name: logs-pv
          persistentVolumeClaim:
            claimName: logs-pvc
        - name: lua-scripts
          configMap:
            name: fluentbit-lua-scripts

      extraVolumeMounts:
        - name: logs-pv
          mountPath: /shared_logs
        - name: lua-scripts
          mountPath: /fluentbit/scripts
          readOnly: true

      config:
        customParsers: |
          [PARSER]
              Name               logfmt_parser
              Format             logfmt
          
          [PARSER]
              Name               java_log_parser
              Format             regex
              Regex              ^(?<time>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) (?<level>[A-Z]+)\s+(?<source>[\w\d]+:\d+) - (?<msg>.*)$
              Time_Key           time
              Time_Format        %Y-%m-%d %H:%M:%S
    

        inputs: |
          [INPUT]
              Name               tail
              Tag                kube.*
              Path               /var/log/containers/*.log
              multiline.parser   docker, cri
              Refresh_Interval   5
              Mem_Buf_Limit      5MB
              Skip_Long_Lines    Off
              Skip_Empty_Lines   On

        filters: |
          [FILTER]
              Name               kubernetes
              Match              kube.*
              Kube_URL           https://kubernetes.default.svc:443
              Kube_CA_File       /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              Kube_Token_File    /var/run/secrets/kubernetes.io/serviceaccount/token
              Kube_Tag_Prefix    kube.var.log.containers.
              Merge_Log          On
              Merge_Log_Key      log_processed
              Annotations        Off
          
          [FILTER]
              Name               rewrite_tag
              Match              kube.*
              Rule               $kubernetes['pod_name'] ^(.*)$ fluentbit-$1 false
              Emitter_Name       re_emitted
          
          [FILTER]
              Name               parser
              Match_Regex        ^fluentbit-argo-.*$|^fluentbit-.*-(etcd|run-console|latch|create-rs|delete-rs)-.*$
              Key_Name           log
              Parser             logfmt_parser
              Preserve_Key       On
              Reserve_Data       On
      
          [FILTER]
              Name               parser
              Match              fluentbit-*-reindex-from-snapshot-*
              Key_Name           log
              Parser             java_log_parser
              Preserve_Key       On
              Reserve_Data       On
          
          [FILTER]
              Name               lua
              Match              fluentbit-*
              script             /fluentbit/scripts/trim.lua
              call               trim_log
    
          [FILTER]
              Name               nest
              Match              fluentbit-*
              Operation          lift
              Nested_under       kubernetes

          [FILTER]
              Name               nest
              Match              fluentbit-*
              Operation          lift
              Nested_under       labels
          
          [FILTER]
              Name               modify
              Match              fluentbit-*
              Rename             container_name container
              Rename             container_image image
              Rename             pod_name pod
              Rename             namespace_name namespace
              Rename             workflows.argoproj.io/workflow workflow
              Remove             _p
              Remove             docker_id
              Remove             container_hash
              Remove             pod-template-hash
              Remove             workflows.argoproj.io/completed
              Remove_regex       ^app\.kubernetes\.io
              Remove_regex       ^batch\.kubernetes\.io
              Move_to_start      log

        outputs: |
          [OUTPUT]
              Name               file
              Match              fluentbit-*
              Path               /shared_logs
              Format             ${OUTPUT_FORMAT}
              Template           {log}

      serviceAccount:
        create: false
        name: migrations-service-account

  # Will likely be required for auto-scaling.
  # Notice that we don't install otel-collector yet, so we can't take advantage of this anyway.
  kube-prometheus-stack:
    version: "72.0.0"
    repository: "https://prometheus-community.github.io/helm-charts"
    values:
      prometheus:
        prometheusSpec:
          serviceMonitorSelector: { }  # Select all ServiceMonitors
          podMonitorSelector: { }      # Select all PodMonitors
          serviceMonitorNamespaceSelector: { }
          podMonitorNamespaceSelector: { }
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "2Gi"
              cpu: "1000m"
          retention: "15d"
          retentionSize: "10GB"
          storageSpec:
            volumeClaimTemplate:
              spec:
                accessModes: [ "ReadWriteOnce" ]
                resources:
                  requests:
                    storage: 50Gi
          thanos:
            enabled: false
        service:
          type: ClusterIP
          port: 9090
      alertmanager:
        enabled: false
      nodeExporter:
        enabled: true  # If OpenTelemetry for is handling host metrics, this can be disabled
      kubeStateMetrics:
        enabled: true
      defaultRules:
        create: false
        rules:
          alertmanager: true
          etcd: true
          general: true
          k8s: true
          kubeApiserver: true
          kubePrometheusNodeAlerting: true
          kubePrometheusNodeRecording: true
          kubernetesAbsent: true
          kubernetesApps: true
          kubernetesResources: true
          kubernetesStorage: true
          kubernetesSystem: true
          kubeScheduler: true
          network: true
          node: true
          prometheus: true
          prometheusOperator: true
      grafana:
        additionalDataSources:
          - name: Jaeger
            type: jaeger
            url: http://jaeger-query:16686
            access: proxy
            isDefault: false
            editable: true

# OPA Gatekeeper dependency to lock down what images we can spin up - not implemented yet
#  - name: gatekeeper
#    version: "3.13.0"
#    repository: "https://open-policy-agent.github.io/gatekeeper/charts"
#    values:
#      auditInterval: 60
#      constraintViolationsLimit: 20
#      enableExternalData: true

  localstack:
    version: "0.6.23"  # Or whichever version you want to use
    repository: "https://localstack.github.io/helm-charts"
    values:
      image:
        repository: "localstack/localstack"
        tag: "4.3.0"

  grafana:
    version: "8.15.0"
    repository: "https://grafana.github.io/helm-charts"
    values:
      ## Grafana data sources configuration
      datasources:
        datasources.yaml:
          apiVersion: 1
          datasources:
            - name: Prometheus
              type: prometheus
              access: proxy
              url: http://prometheus-server.prometheus.svc.cluster.local:9090
              isDefault: true
              editable: true
            - name: Jaeger
              type: jaeger
              access: proxy
              url: http://jaeger-query.jaeger.svc.cluster.local:16686
              isDefault: false
              editable: true
#      ## Set up the sidecar to import the dashboard yaml included in this package
#      sidecar:
#        datasources:
#          enabled: true
#        dashboards:
#          enabled: true
#          label: grafana_dashboard

  jaeger:
    version: "3.2.0"
    repository: "https://jaegertracing.github.io/helm-charts"
    values:
      provisionDataStore:
        cassandra: false
      allInOne:
        enabled: true
      storage:
        type: memory
      agent:
        enabled: false
      collector:
        enabled: false
      query:
        enabled: false