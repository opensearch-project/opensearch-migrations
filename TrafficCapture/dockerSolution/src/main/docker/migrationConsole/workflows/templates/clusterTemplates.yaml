apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: cluster-templates
spec:
  serviceAccountName: argo-workflow-executor
  
  templates:
    - name: elasticsearch-1-5-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: dtzar/helm-kubectl:latest
        command: [ sh, -c ]
        args:
          - |
            set -euo pipefail
            CLUSTER_NAME='{{inputs.parameters.cluster-name}}'
            NAMESPACE='{{inputs.parameters.namespace}}'

            # 1) Write ES 1.5 config to a file, then create/update the ConfigMap idempotently
            cat > /tmp/elasticsearch.yml <<'ESCFG'
            cluster.name: __CLUSTER_NAME__
            network.host: 0.0.0.0
            http.host: 0.0.0.0
            transport.host: 0.0.0.0
            discovery.zen.minimum_master_nodes: 1
            discovery.zen.ping.multicast.enabled: false
            bootstrap.system_call_filter: false
            cloud.aws.region: us-east-2
            cloud.aws.protocol: http
            cloud.aws.s3.endpoint: http://localstack:4566
            ESCFG
            # inject cluster name into the file
            sed -i "s/__CLUSTER_NAME__/${CLUSTER_NAME}/g" /tmp/elasticsearch.yml

            kubectl create configmap "${CLUSTER_NAME}-config" \
              --from-file=elasticsearch.yml=/tmp/elasticsearch.yml \
              -n "${NAMESPACE}" \
              --dry-run=client -o yaml | \
              kubectl label --local -f - migration-test=true cluster-name=${CLUSTER_NAME} -o yaml | \
              kubectl apply -f -

            # 2) Create/update AWS creds secret (for the ES 1.5 cloud-aws plugin to pick up)
            kubectl create secret generic "${CLUSTER_NAME}-aws" \
              --from-literal=AWS_ACCESS_KEY_ID=test \
              --from-literal=AWS_SECRET_ACCESS_KEY=test \
              -n "${NAMESPACE}" \
              --dry-run=client -o yaml | \
              kubectl label --local -f - migration-test=true cluster-name=${CLUSTER_NAME} -o yaml | \
              kubectl apply -f -

            # 3) Apply the Deployment + Service with PATHS for carlchinatomby/elasticsearch:1.5.2-arm64
            cat <<EOF | kubectl apply -f -
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: ${CLUSTER_NAME}
              namespace: ${NAMESPACE}
              labels:
                app: ${CLUSTER_NAME}
                migration-test: "true"
                cluster-name: ${CLUSTER_NAME}
            spec:
              replicas: 1
              selector:
                matchLabels:
                  app: ${CLUSTER_NAME}
              template:
                metadata:
                  labels:
                    app: ${CLUSTER_NAME}
                    migration-test: "true"
                    cluster-name: ${CLUSTER_NAME}
                spec:
                  securityContext:
                    runAsUser: 1000
                    runAsGroup: 1000
                    fsGroup: 1000
                  initContainers:
                    - name: install-s3-plugin
                      image: elasticsearch:1.5.2
                      command: ["sh","-c"]
                      args:
                        - |
                          set -e
                          echo "Starting plugin installation as user $(id)"
                          cd /tmp
                          echo "Downloading plugin..."
                          wget --no-check-certificate --timeout=30 --tries=3 https://download.elastic.co/elasticsearch/elasticsearch-cloud-aws/elasticsearch-cloud-aws-2.5.1.zip || {
                            echo "wget failed, trying curl..."
                            curl -k -L -o elasticsearch-cloud-aws-2.5.1.zip https://download.elastic.co/elasticsearch/elasticsearch-cloud-aws/elasticsearch-cloud-aws-2.5.1.zip
                          }
                          echo "Extracting plugin..."
                          unzip -q elasticsearch-cloud-aws-2.5.1.zip
                          echo "Creating plugin directory..."
                          mkdir -p /usr/share/elasticsearch/plugins/cloud-aws
                          echo "Copying plugin files..."
                          cp *.jar /usr/share/elasticsearch/plugins/cloud-aws/
                          echo "Setting permissions..."
                          chmod -R 755 /usr/share/elasticsearch/plugins/cloud-aws
                          echo "S3 plugin installed successfully"
                          ls -la /usr/share/elasticsearch/plugins/cloud-aws/
                      volumeMounts:
                        - name: plugins
                          mountPath: /usr/share/elasticsearch/plugins
                      securityContext:
                        runAsUser: 1000
                        runAsGroup: 1000
                        runAsNonRoot: true
                  containers:
                    - name: elasticsearch
                      image: elasticsearch:1.5.2
                      imagePullPolicy: IfNotPresent
                      env:
                        - name: ES_HEAP_SIZE
                          value: "512m"
                      envFrom:
                        - secretRef:
                            name: ${CLUSTER_NAME}-aws
                      command: ["/bin/sh","-lc"]
                      args:
                        - >
                          exec /usr/share/elasticsearch/bin/elasticsearch
                            -Des.path.conf=/usr/share/elasticsearch/config
                            -Des.path.data=/usr/share/elasticsearch/data
                            -Des.path.logs=/usr/share/elasticsearch/logs
                            -Des.network.host=0.0.0.0
                            -Des.http.host=0.0.0.0
                            -Des.transport.host=0.0.0.0
                            -Des.cluster.name={{inputs.parameters.cluster-name}}
                            -Des.discovery.zen.minimum_master_nodes=1
                            -Des.bootstrap.system_call_filter=false
                            -Djava.net.preferIPv4Stack=true
                      ports:
                        - containerPort: 9200
                          name: http
                        - containerPort: 9300
                          name: transport
                      readinessProbe:
                        httpGet:
                          path: /
                          port: 9200
                        initialDelaySeconds: 5
                        periodSeconds: 3
                        failureThreshold: 20
                      resources:
                        requests:
                          cpu: "500m"
                          memory: "1Gi"
                        limits:
                          cpu: "1000m"
                          memory: "2Gi"
                      volumeMounts:
                        # Mount ONLY the file (ConfigMap is read-only; avoids scripts/dir creation error)
                        - name: elasticsearch-config
                          mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
                          subPath: elasticsearch.yml
                        # Writable locations
                        - name: elasticsearch-data
                          mountPath: /usr/share/elasticsearch/data
                        - name: elasticsearch-logs
                          mountPath: /usr/share/elasticsearch/logs
                        # Persist the plugin installed in init container
                        - name: plugins
                          mountPath: /usr/share/elasticsearch/plugins
                  volumes:
                    - name: elasticsearch-config
                      configMap:
                        name: ${CLUSTER_NAME}-config
                    - name: elasticsearch-data
                      emptyDir: {}
                    - name: elasticsearch-logs
                      emptyDir: {}
                    - name: plugins
                      emptyDir: {}
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: ${CLUSTER_NAME}
              namespace: ${NAMESPACE}
              labels:
                app: ${CLUSTER_NAME}
                migration-test: "true"
                cluster-name: ${CLUSTER_NAME}
            spec:
              selector:
                app: ${CLUSTER_NAME}
              ports:
                - name: http
                  port: 9200
                  targetPort: 9200
                - name: transport
                  port: 9300
                  targetPort: 9300
            EOF

            # 4) Emit cluster config as output
            cat > /tmp/cluster-config.json <<EOF
            {
              "endpoint": "http://${CLUSTER_NAME}:9200",
              "allow_insecure": true,
              "no_auth": null,
              "version": "ES_1.5"
            }
            EOF

            kubectl create configmap ${CLUSTER_NAME}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              -n ${NAMESPACE} \
              --dry-run=client -o yaml | kubectl apply -f -

            echo "Elasticsearch 1.5 cluster created successfully (ARM-compatible with correct paths)."
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json

    # Elasticsearch 2.4 Single Node Template - Inline Manifests
    - name: elasticsearch-2-4-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: dtzar/helm-kubectl:latest
        command: [sh, -c]
        args:
          - |
            set -euo pipefail
            CLUSTER_NAME='{{inputs.parameters.cluster-name}}'
            NAMESPACE='{{inputs.parameters.namespace}}'

            # 1) Write ES 2.4 config to a file, then create/update the ConfigMap idempotently
            cat > /tmp/elasticsearch.yml <<'ESCFG'
            cluster.name: __CLUSTER_NAME__
            network.host: 0.0.0.0
            http.host: 0.0.0.0
            transport.host: 0.0.0.0
            discovery.zen.minimum_master_nodes: 1
            bootstrap.system_call_filter: false
            cloud.aws.region: us-east-2
            cloud.aws.protocol: http
            cloud.aws.s3.endpoint: http://localstack:4566
            ESCFG
            # inject cluster name into the file
            sed -i "s/__CLUSTER_NAME__/${CLUSTER_NAME}/g" /tmp/elasticsearch.yml

            kubectl create configmap "${CLUSTER_NAME}-config" \
              --from-file=elasticsearch.yml=/tmp/elasticsearch.yml \
              -n "${NAMESPACE}" \
              --dry-run=client -o yaml | \
              kubectl label --local -f - migration-test=true cluster-name=${CLUSTER_NAME} -o yaml | \
              kubectl apply -f -

            # 2) Create/update AWS creds secret (for the ES 2.4 cloud-aws plugin to pick up)
            kubectl create secret generic "${CLUSTER_NAME}-aws" \
              --from-literal=AWS_ACCESS_KEY_ID=test \
              --from-literal=AWS_SECRET_ACCESS_KEY=test \
              -n "${NAMESPACE}" \
              --dry-run=client -o yaml | \
              kubectl label --local -f - migration-test=true cluster-name=${CLUSTER_NAME} -o yaml | \
              kubectl apply -f -

            # 3) Apply the Deployment + Service that mirror our proven setup
            cat <<EOF | kubectl apply -f -
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: ${CLUSTER_NAME}
              namespace: ${NAMESPACE}
              labels:
                app: ${CLUSTER_NAME}
                migration-test: "true"
                cluster-name: ${CLUSTER_NAME}
            spec:
              replicas: 1
              selector:
                matchLabels:
                  app: ${CLUSTER_NAME}
              template:
                metadata:
                  labels:
                    app: ${CLUSTER_NAME}
                    migration-test: "true"
                    cluster-name: ${CLUSTER_NAME}
                spec:
                  securityContext:
                    runAsUser: 1000
                    runAsGroup: 1000
                    fsGroup: 1000
                  initContainers:
                    - name: install-s3-plugin
                      image: elasticsearch:2.4.6
                      command: ["sh","-c"]
                      args:
                        - /usr/share/elasticsearch/bin/plugin install cloud-aws
                      volumeMounts:
                        - name: plugins
                          mountPath: /usr/share/elasticsearch/plugins
                      securityContext:
                        runAsUser: 1000
                        runAsGroup: 1000
                        runAsNonRoot: true
                  containers:
                    - name: elasticsearch
                      image: elasticsearch:2.4.6
                      imagePullPolicy: IfNotPresent
                      envFrom:
                        - secretRef:
                            name: ${CLUSTER_NAME}-aws
                      command: ["/bin/sh","-lc"]
                      args:
                        - >
                          exec /usr/share/elasticsearch/bin/elasticsearch
                            -Des.path.conf=/usr/share/elasticsearch/config
                            -Des.network.host=0.0.0.0
                            -Des.http.host=0.0.0.0
                            -Des.transport.host=0.0.0.0
                            -Des.discovery.zen.minimum_master_nodes=1
                            -Des.bootstrap.system_call_filter=false
                            -Djava.net.preferIPv4Stack=true
                      ports:
                        - containerPort: 9200
                          name: http
                        - containerPort: 9300
                          name: transport
                      readinessProbe:
                        httpGet:
                          path: /
                          port: 9200
                        initialDelaySeconds: 5
                        periodSeconds: 3
                        failureThreshold: 20
                      resources:
                        requests:
                          cpu: "500m"
                          memory: "1Gi"
                        limits:
                          cpu: "1000m"
                          memory: "2Gi"
                      volumeMounts:
                        # Mount ONLY the file (ConfigMap is read-only; avoids scripts/dir creation error)
                        - name: elasticsearch-config
                          mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
                          subPath: elasticsearch.yml
                        # Writable locations
                        - name: elasticsearch-data
                          mountPath: /usr/share/elasticsearch/data
                        - name: elasticsearch-logs
                          mountPath: /usr/share/elasticsearch/logs
                        # Persist the plugin installed in init container
                        - name: plugins
                          mountPath: /usr/share/elasticsearch/plugins
                  volumes:
                    - name: elasticsearch-config
                      configMap:
                        name: ${CLUSTER_NAME}-config
                    - name: elasticsearch-data
                      emptyDir: {}
                    - name: elasticsearch-logs
                      emptyDir: {}
                    - name: plugins
                      emptyDir: {}
            ---
            apiVersion: v1
            kind: Service
            metadata:
              name: ${CLUSTER_NAME}
              namespace: ${NAMESPACE}
              labels:
                app: ${CLUSTER_NAME}
                migration-test: "true"
                cluster-name: ${CLUSTER_NAME}
            spec:
              selector:
                app: ${CLUSTER_NAME}
              ports:
                - name: http
                  port: 9200
                  targetPort: 9200
                - name: transport
                  port: 9300
                  targetPort: 9300
            EOF

            # 4) Emit cluster config as output
            cat > /tmp/cluster-config.json <<EOF
            {
              "endpoint": "http://${CLUSTER_NAME}:9200",
              "allow_insecure": true,
              "no_auth": null,
              "version": "ES_2.4"
            }
            EOF

            kubectl create configmap ${CLUSTER_NAME}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              -n ${NAMESPACE} \
              --dry-run=client -o yaml | kubectl apply -f -

            echo "Elasticsearch 2.4 cluster created successfully (manifests inline)."
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json

    # Elasticsearch 5.6 Single Node Template
    - name: elasticsearch-5-6-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: dtzar/helm-kubectl:latest
        command: [sh, -c]
        args:
          - |
            # Add Elasticsearch Helm repository
            helm repo add elastic https://helm.elastic.co
            helm repo update
            
            # Create Elasticsearch configuration for ES 5.6.16
            cat > /tmp/elasticsearch.yml << EOF
            bootstrap.system_call_filter: false
            network.host: 0.0.0.0
            cloud.aws.access_key: test
            cloud.aws.secret_key: test
            cloud.aws.region: us-east-2
            discovery.zen.minimum_master_nodes: 1
            EOF
            
            # Create Helm values file for ES 5.6.16
            cat > /tmp/es-values.yaml << 'EOF'
            fullnameOverride: {{inputs.parameters.cluster-name}}
            image: "docker.elastic.co/elasticsearch/elasticsearch"
            imageTag: "5.6.16"
            antiAffinity: "soft"
            esJavaOpts: "-Xmx512m -Xms512m"
            protocol: "http"
            replicas: 1
            createCert: false
            clusterHealthCheckParams: "wait_for_status=yellow&timeout=3s"
            readinessProbe:
              failureThreshold: 5
              successThreshold: 2
            extraEnvs:
              - name: "cluster.initial_master_nodes"
                value: ""
              - name: "node.roles"
                value: ""
            persistence:
              enabled: false
            
            extraInitContainers:
              - name: install-s3-plugin
                image: docker.elastic.co/elasticsearch/elasticsearch:5.6.16
                command: ["sh", "-c", "bin/elasticsearch-plugin install --batch repository-s3"]
                volumeMounts:
                  - name: plugins
                    mountPath: /usr/share/elasticsearch/plugins
            
            extraVolumes:
              - name: plugins
                emptyDir: {}
            
            extraVolumeMounts:
              - name: plugins
                mountPath: /usr/share/elasticsearch/plugins
            EOF
            
            # Install Elasticsearch 5.6.16
            helm install {{inputs.parameters.cluster-name}} elastic/elasticsearch \
              --version 8.5.1 \
              --namespace {{inputs.parameters.namespace}} \
              --values /tmp/es-values.yaml \
              --set-file esConfig."elasticsearch\.yml"=/tmp/elasticsearch.yml
            
            # Generate cluster configuration output
            cat > /tmp/cluster-config.json << EOF
            {
              "endpoint": "http://{{inputs.parameters.cluster-name}}:9200",
              "allow_insecure": true,
              "no_auth": null,
              "version": "ES_5.6"
            }
            EOF

            kubectl create configmap {{inputs.parameters.cluster-name}}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              --namespace {{inputs.parameters.namespace}}
            
            echo "Elasticsearch 5.6.16 cluster"
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json

    # Elasticsearch 6.8 Single Node Template
    - name: elasticsearch-6-8-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: dtzar/helm-kubectl:latest
        command: [sh, -c]
        args:
          - |
            # Add Elasticsearch Helm repository
            helm repo add elastic https://helm.elastic.co
            helm repo update
            
            # Create Elasticsearch configuration for ES 6.8.23 OSS (minimal config)
            cat > /tmp/elasticsearch.yml << EOF
            bootstrap.system_call_filter: false
            network.host: 0.0.0.0
            discovery.type: single-node
            transport.port: 9300
            http.port: 9200
            EOF
            
            # Create Helm values file for ES 6.8.23 with OSS image and disabled readiness probe
            cat > /tmp/es-values.yaml << 'EOF'
            fullnameOverride: {{inputs.parameters.cluster-name}}
            image: "docker.elastic.co/elasticsearch/elasticsearch-oss"
            imageTag: "6.8.23"
            antiAffinity: "soft"
            esJavaOpts: "-Xmx512m -Xms512m -XX:UseAVX=0 -Dcom.amazonaws.sdk.disableMBeans=true"
            protocol: "http"
            replicas: 1
            createCert: false
            
            clusterHealthCheckParams: "wait_for_status=yellow&timeout=1s"
            
            masterService: ""
            
            # Disable probes to avoid transient warnings
            readinessProbe: {}
            livenessProbe: {}
            
            extraEnvs:
              - name: "cluster.initial_master_nodes"
                value: ""
              - name: "node.roles"
                value: ""
            
            sysctlInitContainer:
              enabled: true
            
            persistence:
              enabled: false
            
            podDisruptionBudget:
              create: false
              enabled: false
            
            extraInitContainers:
              - name: install-s3-plugin
                image: docker.elastic.co/elasticsearch/elasticsearch-oss:6.8.23
                command: ["sh", "-c", "bin/elasticsearch-plugin install --batch repository-s3"]
                volumeMounts:
                  - name: plugins
                    mountPath: /usr/share/elasticsearch/plugins
              - name: inject-aws-creds
                image: docker.elastic.co/elasticsearch/elasticsearch-oss:6.8.23
                command:
                  - sh
                  - -c
                  - |
                    set -e
                    echo "Creating Elasticsearch keystore and adding AWS credentials"
                    echo 'y' | bin/elasticsearch-keystore create
                    echo "test" | bin/elasticsearch-keystore add --stdin s3.client.default.access_key --force
                    echo "test" | bin/elasticsearch-keystore add --stdin s3.client.default.secret_key --force
                    echo "http://localstack.ma.svc.cluster.local:4566" | bin/elasticsearch-keystore add --stdin s3.client.default.endpoint --force
                    # Copy keystore to shared volume location
                    cp /usr/share/elasticsearch/config/elasticsearch.keystore /shared/elasticsearch.keystore
                    chown 1000:0 /shared/elasticsearch.keystore
                    chmod 660 /shared/elasticsearch.keystore
                    echo "Keystore created and saved to shared volume"
                volumeMounts:
                  - name: elasticsearch-keystore
                    mountPath: /shared
            
            extraVolumes:
              - name: plugins
                emptyDir: {}
              - name: elasticsearch-keystore
                emptyDir: {}
            
            extraVolumeMounts:
              - name: plugins
                mountPath: /usr/share/elasticsearch/plugins
              - name: elasticsearch-keystore
                mountPath: /usr/share/elasticsearch/config/elasticsearch.keystore
                subPath: elasticsearch.keystore
            EOF
            
            # Install Elasticsearch 6.8.23
            helm install {{inputs.parameters.cluster-name}} elastic/elasticsearch \
              --version 8.5.1 \
              --namespace {{inputs.parameters.namespace}} \
              --values /tmp/es-values.yaml \
              --set-file esConfig."elasticsearch\.yml"=/tmp/elasticsearch.yml
            
            # Generate cluster configuration output
            cat > /tmp/cluster-config.json << EOF
            {
              "endpoint": "http://{{inputs.parameters.cluster-name}}:9200",
              "allow_insecure": true,
              "no_auth": true,
              "version": "ES_6.8"
            }
            EOF

            kubectl create configmap {{inputs.parameters.cluster-name}}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              --namespace {{inputs.parameters.namespace}}
            
            echo "Elasticsearch 6.8.23 cluster created successfully"
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json

    # Elasticsearch 7.10 Single Node Template
    - name: elasticsearch-7-10-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: dtzar/helm-kubectl:latest
        command: [sh, -c]
        args:
          - |
            # Add Elasticsearch Helm repository
            helm repo add elastic https://helm.elastic.co
            helm repo update
            
            cat > /tmp/elasticsearch.yml << EOF
            network.host: 0.0.0.0
            discovery.type: single-node
            EOF
            
            cat > /tmp/es-values.yaml << 'EOF'
            fullnameOverride: {{inputs.parameters.cluster-name}}
            image: "docker.elastic.co/elasticsearch/elasticsearch-oss"
            imageTag: "7.10.2"
            antiAffinity: "soft"
            esJavaOpts: "-Xmx512m -Xms512m"
            protocol: "http"
            replicas: 1
            createCert: false
            clusterHealthCheckParams: "wait_for_status=yellow&timeout=3s"
            readinessProbe:
              failureThreshold: 5
              successThreshold: 2
            extraEnvs:
              - name: node.roles
                value: "master,data,ingest"
              - name: "cluster.initial_master_nodes"
                value: ""
              - name: "AWS_REGION"
                value: "us-east-2"
            
            persistence:
              enabled: false
            
            extraInitContainers:
              - name: install-s3-plugin
                image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.10.2
                command: ["sh", "-c", "bin/elasticsearch-plugin install --batch repository-s3"]
                volumeMounts:
                  - name: plugins
                    mountPath: /usr/share/elasticsearch/plugins
              - name: inject-aws-creds
                image: docker.elastic.co/elasticsearch/elasticsearch-oss:7.10.2
                command:
                  - sh
                  - -c
                  - |
                    set -e
                    echo "Creating Elasticsearch keystore and adding AWS credentials"
                    echo 'y' | bin/elasticsearch-keystore create
                    echo "test" | bin/elasticsearch-keystore add --stdin s3.client.default.access_key --force
                    echo "test" | bin/elasticsearch-keystore add --stdin s3.client.default.secret_key --force
                    # Copy keystore to shared volume location
                    cp /usr/share/elasticsearch/config/elasticsearch.keystore /shared/elasticsearch.keystore
                    echo "Keystore created and saved to shared volume"
                volumeMounts:
                  - name: elasticsearch-keystore
                    mountPath: /shared
            
            extraVolumes:
              - name: plugins
                emptyDir: {}
              - name: elasticsearch-keystore
                emptyDir: {}
            
            extraVolumeMounts:
              - name: plugins
                mountPath: /usr/share/elasticsearch/plugins
              - name: elasticsearch-keystore
                mountPath: /usr/share/elasticsearch/config/elasticsearch.keystore
                subPath: elasticsearch.keystore
            EOF
            
            helm install {{inputs.parameters.cluster-name}} elastic/elasticsearch \
              --version 8.5.1 \
              --namespace {{inputs.parameters.namespace}} \
              --values /tmp/es-values.yaml \
              --set-file esConfig."elasticsearch\.yml"=/tmp/elasticsearch.yml
            
            # Generate cluster configuration output
            cat > /tmp/cluster-config.json << EOF
            {
              "endpoint": "http://{{inputs.parameters.cluster-name}}:9200",
              "allow_insecure": true,
              "no_auth": null,
              "version": "ES_7.10"
            }
            EOF

            kubectl create configmap {{inputs.parameters.cluster-name}}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              --namespace {{inputs.parameters.namespace}}
            
            echo "Elasticsearch 7.10 cluster"
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json

    # Elasticsearch 8.19 Multi Node Template
    - name: elasticsearch-8-19-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
          - name: replicas
            value: "3"
      container:
        image: dtzar/helm-kubectl:latest
        command: [sh, -c]
        args:
          - |
            set -euo pipefail
            
            helm repo add elastic https://helm.elastic.co
            helm repo update
            
            # ES config: minimal, no security, explicit discovery, open bind
            cat > /tmp/elasticsearch.yml <<'EOF'
            cluster.name: ${CLUSTER_NAME}
            network.host: 0.0.0.0
            # Cut noise if anything ever hits HTTP by mistake.
            logger.org.elasticsearch.http.netty4.Netty4HttpServerTransport: error
            EOF
            
            # Values: tiny heap, 3 replicas, ephemeral, sysctl init
            # NOTE: Do NOT set node.roles, discovery.seed_hosts, or cluster.initial_master_nodes here.
            cat > /tmp/es-values.yaml <<'EOF'
            fullnameOverride: {{inputs.parameters.cluster-name}}
            image: "docker.elastic.co/elasticsearch/elasticsearch"
            imageTag: "8.19.0"
            replicas: {{inputs.parameters.replicas}}
            antiAffinity: "soft"
            protocol: "https"
            esJavaOpts: "-Xmx512m -Xms512m"
            persistence:
              enabled: false
            # Ensure vm.max_map_count etc. on Minikube
            sysctlInitContainer:
              enabled: true
            # Add AWS region to silence S3 plugin INFOs
            extraEnvs:
              - name: AWS_REGION
                value: "us-east-2"
              - name: AWS_DEFAULT_REGION
                value: "us-east-2"
              - name: AWS_ACCESS_KEY_ID
                value: "test"
              - name: AWS_SECRET_ACCESS_KEY
                value: "test"
              - name: AWS_EC2_METADATA_DISABLED
                value: "true"
              - name: AWS_S3_FORCE_PATH_STYLE
                value: "true"
            extraVolumes:
            - name: es-s3-credentials
              secret:
                secretName: es-s3-credentials
                optional: true  # allows running without S3 if Secret is missing
            # directory to hold the keystore (not a single-file subPath)
            - name: elasticsearch-keystore-dir
              emptyDir: {}
            extraVolumeMounts:
            - name: es-s3-credentials
              mountPath: /mnt/es-s3-credentials
              readOnly: true
            # mount the dedicated directory; we will create the keystore inside it
            - name: elasticsearch-keystore-dir
              mountPath: /usr/share/elasticsearch/config/keystore-mount
            extraInitContainers:
            - name: inject-s3-keystore
              image: docker.elastic.co/elasticsearch/elasticsearch:8.19.0
              command: [bash, -lc]
              args:
                - |
                  set -euo pipefail
                  ES_BIN=/usr/share/elasticsearch/bin/elasticsearch-keystore
                  KS_DIR=/usr/share/elasticsearch/config/keystore-mount
                  KS_FILE="$KS_DIR/elasticsearch.keystore"
                  DEFAULT_KS=/usr/share/elasticsearch/config/elasticsearch.keystore
            
                  echo "[inject-s3-keystore] Using keystore dir: $KS_DIR"
                  mkdir -p "$KS_DIR"
            
                  # Point keystore tool at our mounted directory
                  export ES_PATH_CONF="$KS_DIR"
          
                  # Create keystore if needed
                  if [ ! -s "$KS_FILE" ]; then
                    echo "[inject-s3-keystore] Creating keystore..."
                    $ES_BIN create
                  fi
                  
                  put_secret () {
                    local key="$1" file="$2"
                    if [ -s "$file" ]; then
                      echo "Setting keystore [$key] from $file"
                      cat "$file" | $ES_BIN add -xf "$key"
                    fi
                  }
            
                  put_plain () {
                    local key="$1" file="$2"
                    if [ -s "$file" ]; then
                      echo "Setting plaintext setting [$key] from $file"
                      cat "$file" | $ES_BIN add -xf "$key"
                    fi
                  }
                  
                  put_secret "s3.client.default.access_key" /mnt/es-s3-credentials/access_key
                  put_secret "s3.client.default.secret_key" /mnt/es-s3-credentials/secret_key
                  put_plain "s3.client.default.endpoint" mnt/es-s3-credentials/endpoint
                  put_plain "s3.client.default.path_style_access" /mnt/es-s3-credentials/path_style_access
                  put_plain "s3.client.default.region" /mnt/es-s3-credentials/region
            
            
                  echo "Keystore contents now:"
                  $ES_BIN list || true
                  
                  # Ensure ES (uid 1000) can read the file
                  chown 1000:0 "$KS_FILE" || true
                  chmod 660 "$KS_FILE" || true
                  # Make default path resolve to our mounted keystore via symlink
                  ln -sf "$KS_FILE" "$DEFAULT_KS"
                  echo "[inject-s3-keystore] Symlinked $DEFAULT_KS -> $KS_FILE"
                  echo "[inject-s3-keystore] done"
              volumeMounts:
                - name: es-s3-credentials
                  mountPath: /mnt/es-s3-credentials
                  readOnly: true
                - name: elasticsearch-keystore-dir
                  mountPath: /usr/share/elasticsearch/config/keystore-mount
              securityContext:
                runAsUser: 0
                runAsGroup: 0
                runAsNonRoot: false
            # Probes overriden to use HTTPS + basic auth with the chart's password
            readinessProbe: {}
            livenessProbe: {}
            EOF
    
            # Create AWS credentials secret for S3 repository BEFORE Helm install
            kubectl create secret generic es-s3-credentials \
              --from-literal=access_key=test \
              --from-literal=secret_key=test \
              --from-literal=endpoint=http://localstack:4566 \
              --from-literal=path_style_access=true \
              --from-literal=region=us-east-2 \
              -n {{inputs.parameters.namespace}} \
              --dry-run=client -o yaml | kubectl apply -f -
            
            # Install
            helm install {{inputs.parameters.cluster-name}} elastic/elasticsearch \
            --version 8.5.1 \
            --namespace {{inputs.parameters.namespace}} \
            --values /tmp/es-values.yaml \
            --set-file esConfig."elasticsearch\.yml"=/tmp/elasticsearch.yml
    
            # Minimal cluster-config for your console tools (no auth)
            cat > /tmp/cluster-config.json <<EOF
            {
              "endpoint": "https://{{inputs.parameters.cluster-name}}:9200",
              "allow_insecure": true,
              "no_auth": false,
              "version": "ES_8.19"
            }
            EOF
            
            # Create the bucket in LocalStack (path-style)
            kubectl -n {{inputs.parameters.namespace}} run --rm -i --tty aws \
              --restart=Never --image=amazon/aws-cli --command -- \
              sh -lc '
                export AWS_ACCESS_KEY_ID=test
                export AWS_SECRET_ACCESS_KEY=test
                export AWS_DEFAULT_REGION=us-east-2
                aws --endpoint-url http://localstack:4566 s3api create-bucket \
                  --bucket es-snapshots \
                  --create-bucket-configuration LocationConstraint=us-east-2 || true
              '
            
            PW=$(kubectl -n {{inputs.parameters.namespace}} get secret {{inputs.parameters.cluster-name}}-credentials -o jsonpath='{.data.password}' | base64 -d)
  
            # Remove readiness probe to make pods show as ready
            kubectl patch statefulset -n {{inputs.parameters.namespace}} {{inputs.parameters.cluster-name}} --type='json' -p='[{"op": "remove", "path": "/spec/template/spec/containers/0/readinessProbe"}]'
            
            # Wait for pods to be ready
            kubectl wait --for=condition=ready pod -l app={{inputs.parameters.cluster-name}} -n {{inputs.parameters.namespace}} --timeout=300s
            
            # Wait for Elasticsearch to be fully ready
            sleep 60
            
            # Setup S3 snapshot repository
            kubectl exec -n {{inputs.parameters.namespace}} {{inputs.parameters.cluster-name}}-0 -- curl -sSk -u "elastic:${PW}" -H "Content-Type: application/json" \
              -X PUT https://127.0.0.1:9200/_snapshot/es-snapshots \
              -d '{
                "type": "s3",
                "settings": {
                  "bucket": "es-snapshots",
                  "client": "default"
                }
              }' || echo "S3 repository setup failed (expected without proper credentials)"
    
            kubectl create configmap {{inputs.parameters.cluster-name}}-migration-config \
            --from-file=cluster-config=/tmp/cluster-config.json \
            --namespace {{inputs.parameters.namespace}}
    
            echo "Elasticsearch 8.19 (3-node) cluster created with S3 snapshot repository"
            echo "Cluster config:"
            cat /tmp/cluster-config.json

    # OpenSearch 1.3 Single Node Template
    - name: opensearch-1-3-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: dtzar/helm-kubectl:latest
        command: [sh, -c]
        args:
          - |
            # Add OpenSearch Helm repository
            helm repo add opensearch https://opensearch-project.github.io/helm-charts/
            helm repo update
            
            # Create OpenSearch configuration
            cat > /tmp/opensearch.yml << EOF
            cluster.name: {{inputs.parameters.cluster-name}}
            network.host: 0.0.0.0
            discovery.type: single-node
            EOF
            
            # Create OpenSearch values file
            cat > /tmp/opensearch-values.yaml << 'EOF'
            fullnameOverride: {{inputs.parameters.cluster-name}}
            nodeGroup: ""
            image:
              repository: "opensearchproject/opensearch"
              tag: "1.3.20"
            singleNode: true
            replicas: 1
            resources:
              requests:
                cpu: "500m"
                memory: "1Gi"
              limits:
                cpu: "1000m"
                memory: "2Gi"
            persistence:
              enabled: false
            opensearchJavaOpts: "-Xmx1g -Xms1g"
            plugins:
              enabled: true
              installList:
                - "repository-s3"
            EOF
            
            # Install OpenSearch 1.3
            helm install {{inputs.parameters.cluster-name}} opensearch/opensearch \
              --namespace {{inputs.parameters.namespace}} \
              --values /tmp/opensearch-values.yaml \
              --set-file config."opensearch\.yml"=/tmp/opensearch.yml
            
            # Generate cluster configuration output
            cat > /tmp/cluster-config.json << EOF
            {
              "endpoint": "https://{{inputs.parameters.cluster-name}}:9200",
              "allow_insecure": true,
              "version": "OS_1.3",
              "basic_auth": {
                "username": "admin",
                "password": "admin"
              }
            }
            EOF

            kubectl create configmap {{inputs.parameters.cluster-name}}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              --namespace {{inputs.parameters.namespace}}
            
            echo "OpenSearch 1.3 cluster created successfully"
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json

    # OpenSearch 2.19 Single Node Template
    - name: opensearch-2-19-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: dtzar/helm-kubectl:latest
        command: [sh, -c]
        args:
          - |
            # Add OpenSearch Helm repository
            helm repo add opensearch https://opensearch-project.github.io/helm-charts/
            helm repo update
            
            # Create OpenSearch configuration
            cat > /tmp/opensearch.yml << EOF
            cluster.name: {{inputs.parameters.cluster-name}}
            network.host: 0.0.0.0
            discovery.type: single-node
            EOF
            
            # Create OpenSearch values file
            cat > /tmp/opensearch-values.yaml << 'EOF'
            fullnameOverride: {{inputs.parameters.cluster-name}}
            nodeGroup: ""
            image:
              repository: "opensearchproject/opensearch"
              tag: "2.19.1"
            singleNode: true
            replicas: 1
            extraEnvs:
              - name: "OPENSEARCH_INITIAL_ADMIN_PASSWORD"
                value: "myStrongPassword123!"
            resources:
              requests:
                cpu: "500m"
                memory: "1Gi"
              limits:
                cpu: "1000m"
                memory: "2Gi"
            persistence:
              enabled: false
            opensearchJavaOpts: "-Xmx1g -Xms1g"
            plugins:
              enabled: true
              installList:
                - "repository-s3"
            EOF
            
            # Install OpenSearch 2.19.1
            helm install {{inputs.parameters.cluster-name}} opensearch/opensearch \
              --namespace {{inputs.parameters.namespace}} \
              --values /tmp/opensearch-values.yaml \
              --set-file config."opensearch\.yml"=/tmp/opensearch.yml
            
            # Generate cluster configuration output
            cat > /tmp/cluster-config.json << EOF
            {
              "endpoint": "https://{{inputs.parameters.cluster-name}}:9200",
              "allow_insecure": true,
              "version": "OS_2.19",
              "basic_auth": {
                "username": "admin",
                "password": "myStrongPassword123!"
              }
            }
            EOF

            kubectl create configmap {{inputs.parameters.cluster-name}}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              --namespace {{inputs.parameters.namespace}}
            
            echo "OpenSearch 2.19.1 cluster created successfully"
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json

    # OpenSearch 3.1 Single Node Template
    - name: opensearch-3-1-single-node
      inputs:
        parameters:
          - name: cluster-name
          - name: namespace
      container:
        image: dtzar/helm-kubectl:latest
        command: [sh, -c]
        args:
          - |
            helm repo add opensearch https://opensearch-project.github.io/helm-charts/
            helm repo update
            
            cat > /tmp/opensearch.yml << EOF
            cluster.name: {{inputs.parameters.cluster-name}}
            network.host: 0.0.0.0
            discovery.type: single-node
            EOF
            
            cat > /tmp/opensearch-values.yaml << 'EOF'
            fullnameOverride: {{inputs.parameters.cluster-name}}
            nodeGroup: ""
            image:
              repository: "opensearchproject/opensearch"
              tag: "3.1.0"
            singleNode: true
            replicas: 1
            extraEnvs:
              - name: "OPENSEARCH_INITIAL_ADMIN_PASSWORD"
                value: "MyStr0ngPassw0rd!"
            resources:
              requests:
                cpu: "500m"
                memory: "1Gi"
              limits:
                cpu: "1000m"
                memory: "2Gi"
            persistence:
              enabled: false
            opensearchJavaOpts: "-Xmx1g -Xms1g"
            plugins:
              enabled: true
              installList:
                - "repository-s3"
            EOF
            
            helm install {{inputs.parameters.cluster-name}} opensearch/opensearch \
              --namespace {{inputs.parameters.namespace}} \
              --values /tmp/opensearch-values.yaml \
              --set-file config."opensearch\.yml"=/tmp/opensearch.yml
            
            cat > /tmp/cluster-config.json << EOF
            {
              "endpoint": "https://{{inputs.parameters.cluster-name}}:9200",
              "allow_insecure": true,
              "version": "OS_3.1",
              "basic_auth": {
                "username": "admin",
                "password": "MyStr0ngPassw0rd!"
              }
            }
            EOF
            
            kubectl create configmap {{inputs.parameters.cluster-name}}-migration-config \
              --from-file=cluster-config=/tmp/cluster-config.json \
              --namespace {{inputs.parameters.namespace}}
            
            echo "OpenSearch 3.1.0 cluster created successfully"
            echo "Cluster config:"
            cat /tmp/cluster-config.json
      outputs:
        parameters:
          - name: cluster-config
            valueFrom:
              path: /tmp/cluster-config.json