# Index Configuration Tool

Python package that automates the creation of indices on a target cluster based on the contents of a source cluster. 
Index settings and index mappings are correctly copied over, but no data is transferred. 
This tool seeks to eliminate the need to [specify index templates](https://github.com/awslabs/logstash-output-amazon_es#optional-parameters) when migrating data from one cluster to another.
The tool currently supports ElasticSearch or OpenSearch as source and target.

## Parameters

The first required input to the tool is a path to a [Data Prepper](https://github.com/opensearch-project/data-prepper) pipeline YAML file, which is parsed to obtain the source and target cluster endpoints.
The second required input is an output path to which a modified version of the pipeline YAML file is written.
This version of the pipeline adds an index inclusion configuration to the sink, specifying only those indices that were created by the index configuration tool.
The tool also supports several optional flags:

| Flag | Purpose |
| ------------- | ------------- |
| `-h, --help`    | Prints help text and exits |
| `--report, -r`  | Prints a report of indices indicating which ones will be created, along with indices that are identical or have conflicting settings/mappings.  |
| `--dryrun`      | Skips the actual creation of indices on the target cluster |

### Reporting

If `--report` is specified, the tool prints all processed indices organized into 3 buckets:
* Successfully created on the target cluster
* Skipped due to a conflict in settings/mappings
* Skipped since the index configuration is identical on source and target

## Current Limitations

* Only supports ElasticSearch and OpenSearch endpoints for source and target
* Only supports basic auth
* Type mappings for legacy indices are not handled
* Index templates and index aliases are not copied
* Index health is not validated after creation

## Usage

### Command-Line

#### Setup:

* [Clone](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository) this GitHub repo
* Install [Python](https://www.python.org/)
* Ensure that [pip](https://pip.pypa.io/en/stable/installation/#) is installed
* (Optional) Set up and activate a [virtual environment](https://packaging.python.org/en/latest/tutorials/installing-packages/#creating-and-using-virtual-environments)

Navigate to the cloned GitHub repo. Then, install the required Python dependencies by running:

```shell
python -m pip install -r index_configuration_tool/requirements.txt
```

#### Execution:

After [setup](#setup), the tool can be executed using:

```shell
python index_configuration_tool/pre_migration.py <pipeline_yaml_path> <output_file>
```

### Docker

First build the Docker image from the `Dockerfile`:

```shell
docker build -t fetch-migration .
```

Then run the `fetch-migration` image.
Replace `<pipeline_yaml_path>` in the command below with the path to your Logstash config file:

```shell
docker run -p 4900:4900 -v <pipeline_yaml_path>:/code/input.yaml ict
```

## Development

The source code for the tool is located under the `index_configuration_tool/` directory. Please refer to the [Setup](#setup) section to ensure that the necessary dependencies are installed prior to development.

Additionally, you'll also need to install development dependencies by running:

```shell
python -m pip install -r index_configuration_tool/dev-requirements.txt
```

### Unit Tests

Unit tests are located in a sub-directory named `tests`. Unit tests can be run using:

```shell
python -m unittest
```

### Coverage

Code coverage metrics can be generated by first running unit tests using _coverage run_:

```shell
python -m coverage run -m unittest
```

Then a report can either be printed on the command line or generated as HTML.
Note that the `--omit` parameter must be specified to avoid tracking code coverage on unit test code:

```shell
python -m coverage report --omit "*/tests/*"
python -m coverage html --omit "*/tests/*"
```